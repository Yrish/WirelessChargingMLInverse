Logging enabled.
./wcmi.py train --dense --reverse --load-data=data/4th_dataset_noid.csv --save-model=dist/reverse_dense_00_initial.pt --save-data=dist/reverse_train_dense_mse_00_initial.csv --log=dist/log/reverse_train_dense_00_initial.log --log-truncate --num-epochs=10 --status-every-epoch=1
device: cpu

Beginning epoch #1/10.
  Beginning sample #1/6,327 (epoch #1/10).
    MSE loss, mean of columns: 1,631,439.625000
  Beginning sample #1,025/6,327 (epoch #1/10).
    MSE loss, mean of columns: 2,503,012.500000
  Beginning sample #2,049/6,327 (epoch #1/10).
    MSE loss, mean of columns: 2,103,738.750000
  Beginning sample #3,009/6,327 (epoch #1/10).
    MSE loss, mean of columns: 2,873,500.000000
  Beginning sample #4,033/6,327 (epoch #1/10).
    MSE loss, mean of columns: 2,538,005.500000
  Beginning sample #5,057/6,327 (testing phase) (epoch #1/10).
    MSE loss, mean of columns: 2,222,052.250000
  Beginning sample #6,017/6,327 (testing phase) (epoch #1/10).
    MSE loss, mean of columns: 2,441,703.750000
Done training epoch #1/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,898,326.000000 (2,451,906.750000) vs. 11,683,894.000000 (2,409,749.250000) (lower is more accurate)).

Beginning epoch #2/10.
  Beginning sample #1/6,327 (epoch #2/10).
    MSE loss, mean of columns: 2,310,290.500000
  Beginning sample #1,025/6,327 (epoch #2/10).
    MSE loss, mean of columns: 2,560,862.000000
  Beginning sample #2,049/6,327 (epoch #2/10).
    MSE loss, mean of columns: 2,246,787.500000
  Beginning sample #3,009/6,327 (epoch #2/10).
    MSE loss, mean of columns: 2,837,411.250000
  Beginning sample #4,033/6,327 (epoch #2/10).
    MSE loss, mean of columns: 2,539,459.750000
  Beginning sample #5,057/6,327 (testing phase) (epoch #2/10).
    MSE loss, mean of columns: 2,220,860.000000
  Beginning sample #6,017/6,327 (testing phase) (epoch #2/10).
    MSE loss, mean of columns: 2,357,450.000000
Done training epoch #2/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,849,575.000000 (2,442,691.500000) vs. 11,713,388.000000 (2,416,328.500000) (lower is more accurate)).

Beginning epoch #3/10.
  Beginning sample #1/6,327 (epoch #3/10).
    MSE loss, mean of columns: 2,308,585.250000
  Beginning sample #1,025/6,327 (epoch #3/10).
    MSE loss, mean of columns: 2,451,646.750000
  Beginning sample #2,049/6,327 (epoch #3/10).
    MSE loss, mean of columns: 2,246,109.500000
  Beginning sample #3,009/6,327 (epoch #3/10).
    MSE loss, mean of columns: 2,835,476.750000
  Beginning sample #4,033/6,327 (epoch #3/10).
    MSE loss, mean of columns: 2,622,930.000000
  Beginning sample #5,057/6,327 (testing phase) (epoch #3/10).
    MSE loss, mean of columns: 2,169,369.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #3/10).
    MSE loss, mean of columns: 2,417,650.250000
Done training epoch #3/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,865,750.000000 (2,445,934.500000) vs. 11,741,713.000000 (2,421,976.000000) (lower is more accurate)).

Beginning epoch #4/10.
  Beginning sample #1/6,327 (epoch #4/10).
    MSE loss, mean of columns: 2,259,350.500000
  Beginning sample #1,025/6,327 (epoch #4/10).
    MSE loss, mean of columns: 2,617,641.250000
  Beginning sample #2,049/6,327 (epoch #4/10).
    MSE loss, mean of columns: 2,163,314.750000
  Beginning sample #3,009/6,327 (epoch #4/10).
    MSE loss, mean of columns: 2,906,240.750000
  Beginning sample #4,033/6,327 (epoch #4/10).
    MSE loss, mean of columns: 2,569,249.750000
  Beginning sample #5,057/6,327 (testing phase) (epoch #4/10).
    MSE loss, mean of columns: 2,169,369.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #4/10).
    MSE loss, mean of columns: 2,441,702.500000
Done training epoch #4/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,834,404.000000 (2,439,407.000000) vs. 11,761,758.000000 (2,425,911.500000) (lower is more accurate)).

Beginning epoch #5/10.
  Beginning sample #1/6,327 (epoch #5/10).
    MSE loss, mean of columns: 2,259,352.500000
  Beginning sample #1,025/6,327 (epoch #5/10).
    MSE loss, mean of columns: 2,618,598.750000
  Beginning sample #2,049/6,327 (epoch #5/10).
    MSE loss, mean of columns: 2,163,312.000000
  Beginning sample #3,009/6,327 (epoch #5/10).
    MSE loss, mean of columns: 2,876,450.500000
  Beginning sample #4,033/6,327 (epoch #5/10).
    MSE loss, mean of columns: 2,569,247.750000
  Beginning sample #5,057/6,327 (testing phase) (epoch #5/10).
    MSE loss, mean of columns: 2,224,752.000000
  Beginning sample #6,017/6,327 (testing phase) (epoch #5/10).
    MSE loss, mean of columns: 2,468,289.000000
Done training epoch #5/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,881,351.000000 (2,449,307.250000) vs. 11,745,413.000000 (2,422,532.000000) (lower is more accurate)).

Beginning epoch #6/10.
  Beginning sample #1/6,327 (epoch #6/10).
    MSE loss, mean of columns: 2,259,350.500000
  Beginning sample #1,025/6,327 (epoch #6/10).
    MSE loss, mean of columns: 2,587,959.000000
  Beginning sample #2,049/6,327 (epoch #6/10).
    MSE loss, mean of columns: 2,193,100.000000
  Beginning sample #3,009/6,327 (epoch #6/10).
    MSE loss, mean of columns: 2,904,306.500000
  Beginning sample #4,033/6,327 (epoch #6/10).
    MSE loss, mean of columns: 2,539,459.750000
  Beginning sample #5,057/6,327 (testing phase) (epoch #6/10).
    MSE loss, mean of columns: 2,192,267.250000
  Beginning sample #6,017/6,327 (testing phase) (epoch #6/10).
    MSE loss, mean of columns: 2,359,930.250000
Done training epoch #6/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,794,331.000000 (2,432,054.250000) vs. 11,740,426.000000 (2,421,559.250000) (lower is more accurate)).

Beginning epoch #7/10.
  Beginning sample #1/6,327 (epoch #7/10).
    MSE loss, mean of columns: 2,310,290.500000
  Beginning sample #1,025/6,327 (epoch #7/10).
    MSE loss, mean of columns: 2,589,186.500000
  Beginning sample #2,049/6,327 (epoch #7/10).
    MSE loss, mean of columns: 2,246,824.500000
  Beginning sample #3,009/6,327 (epoch #7/10).
    MSE loss, mean of columns: 2,876,425.500000
  Beginning sample #4,033/6,327 (epoch #7/10).
    MSE loss, mean of columns: 2,539,457.250000
  Beginning sample #5,057/6,327 (testing phase) (epoch #7/10).
    MSE loss, mean of columns: 2,189,317.250000
  Beginning sample #6,017/6,327 (testing phase) (epoch #7/10).
    MSE loss, mean of columns: 2,443,422.250000
Done training epoch #7/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,857,042.000000 (2,443,618.500000) vs. 11,725,737.000000 (2,418,691.000000) (lower is more accurate)).

Beginning epoch #8/10.
  Beginning sample #1/6,327 (epoch #8/10).
    MSE loss, mean of columns: 2,311,281.750000
  Beginning sample #1,025/6,327 (epoch #8/10).
    MSE loss, mean of columns: 2,587,016.750000
  Beginning sample #2,049/6,327 (epoch #8/10).
    MSE loss, mean of columns: 2,103,778.500000
  Beginning sample #3,009/6,327 (epoch #8/10).
    MSE loss, mean of columns: 2,822,743.500000
  Beginning sample #4,033/6,327 (epoch #8/10).
    MSE loss, mean of columns: 2,590,392.750000
  Beginning sample #5,057/6,327 (testing phase) (epoch #8/10).
    MSE loss, mean of columns: 2,222,561.250000
  Beginning sample #6,017/6,327 (testing phase) (epoch #8/10).
    MSE loss, mean of columns: 2,441,722.250000
Done training epoch #8/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,917,647.000000 (2,456,557.000000) vs. 11,773,766.000000 (2,428,253.000000) (lower is more accurate)).

Beginning epoch #9/10.
  Beginning sample #1/6,327 (epoch #9/10).
    MSE loss, mean of columns: 2,259,368.000000
  Beginning sample #1,025/6,327 (epoch #9/10).
    MSE loss, mean of columns: 2,618,978.000000
  Beginning sample #2,049/6,327 (epoch #9/10).
    MSE loss, mean of columns: 2,163,350.000000
  Beginning sample #3,009/6,327 (epoch #9/10).
    MSE loss, mean of columns: 2,906,209.500000
  Beginning sample #4,033/6,327 (epoch #9/10).
    MSE loss, mean of columns: 2,539,449.250000
  Beginning sample #5,057/6,327 (testing phase) (epoch #9/10).
    MSE loss, mean of columns: 2,163,343.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #9/10).
    MSE loss, mean of columns: 2,443,393.250000
Done training epoch #9/10 (testing MSE norm (mean) vs. training MSE norm (mean): 11,845,801.000000 (2,442,263.500000) vs. 11,718,967.000000 (2,417,637.750000) (lower is more accurate)).

Beginning epoch #10/10.
  Beginning sample #1/6,327 (epoch #10/10).
    MSE loss, mean of columns: 2,259,359.750000
  Beginning sample #1,025/6,327 (epoch #10/10).
    MSE loss, mean of columns: 2,589,173.500000
  Beginning sample #2,049/6,327 (epoch #10/10).
    MSE loss, mean of columns: 2,315,426.750000
  Beginning sample #3,009/6,327 (epoch #10/10).
    MSE loss, mean of columns: 2,924,062.000000
  Beginning sample #4,033/6,327 (epoch #10/10).
    MSE loss, mean of columns: 2,557,566.500000
  Beginning sample #5,057/6,327 (testing phase) (epoch #10/10).
    MSE loss, mean of columns: 2,773,448.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #10/10).
    MSE loss, mean of columns: 2,538,870.250000
Done training epoch #10/10 (testing MSE norm (mean) vs. training MSE norm (mean): 13,863,640.000000 (2,857,809.500000) vs. 12,590,576.000000 (2,601,264.500000) (lower is more accurate)).

Done training last epoch.  Preparing statistics...

Last testing MSE   (norm) (mean) : <        45.263630,        781.426147,      1,268.540649, 13,856,970.000000,    429,983.312500> (13,863,640.000000) ( 2,857,809.500000)
Last testing RMSE  (norm) (mean) : <         6.727825,         27.954000,         35.616577,      3,722.495117,        655.731140> (     3,780.085693) (       889.704895)
Last training MSE  (norm) (mean) : <        46.431702,        762.710144,      1,232.588135, 12,583,544.000000,    420,735.687500> (12,590,576.000000) ( 2,601,264.500000)
Last training RMSE (norm) (mean) : <         6.814081,         27.617207,         35.108234,      3,547.329102,        648.641418> (     3,606.427979) (       853.102051)

Label column names               : <         kdiff[%],         Bleak[uT],    V_PriWind[cm3],    V_PriCore[cm3],           Pout[W]>

(Reversed model: labels are simulation outputs, not inputs.)
All labels mean    (norm) (mean) : <         9.776808,         26.101175,         88.323395,      3,365.576172,        656.228149> (     3,430.206299) (       829.201172)
All labels var     (norm) (mean) : <        19.390743,        399.580109,        620.851685,  6,775,504.500000,    193,356.734375> ( 6,778,263.000000) ( 1,393,980.250000)
All labels stddev  (norm) (mean) : <         4.403492,         19.989500,         24.916895,      2,602.979980,        439.723480> (     2,640.057129) (       618.402649)

All labels min     (norm) (mean) : <         0.012835,          2.900000,         38.160000,        800.000000,         50.312965> (       802.493591) (       178.277161)
...1st quartile    (norm) (mean) : <         7.866466,         12.751261,         67.320000,      1,250.000000,        309.686279> (     1,289.636475) (       329.524811)
All labels median  (norm) (mean) : <        10.647444,         20.200001,         88.919998,      2,450.000000,        513.998108> (     2,505.019287) (       616.753052)
...3rd quartile    (norm) (mean) : <        12.842000,         32.799999,        107.279999,      5,000.000000,        925.467468> (     5,086.181152) (     1,215.677856)
All labels max     (norm) (mean) : <        17.763830,        153.600006,        140.759995,      8,450.000000,      1,968.984619> (     8,678.889648) (     2,146.221680)

Wrote MSE errors (testing MSE for each epoch and then training MSE for each epoch) to `dist/reverse_train_dense_mse_00_initial.csv'.

Saved trained model to `dist/reverse_dense_00_initial.pt'.

Done training all epochs.
Have a good day.
