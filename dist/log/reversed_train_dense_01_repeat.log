Logging enabled.
./wcmi.py train --dense --reverse --load-model=dist/reversed_dense_00_initial.pt --load-data=data/4th_dataset_noid.csv --save-model=dist/reversed_dense.pt --save-data=dist/reversed_train_dense_mse_01_repeat.csv --log=dist/log/reversed_train_dense_01_repeat.log --log-truncate
device: cpu

Beginning epoch #1/100.
  Beginning sample #1/6,327 (epoch #1/100).
    MSE loss, mean of columns: 3,429,928.500000
  Beginning sample #1,025/6,327 (epoch #1/100).
    MSE loss, mean of columns: 2,665,610.250000
  Beginning sample #2,049/6,327 (epoch #1/100).
    MSE loss, mean of columns: 2,800,302.000000
  Beginning sample #3,009/6,327 (epoch #1/100).
    MSE loss, mean of columns: 1,534,864.250000
  Beginning sample #4,033/6,327 (epoch #1/100).
    MSE loss, mean of columns: 3,518,058.750000
  Beginning sample #5,057/6,327 (testing phase) (epoch #1/100).
    MSE loss, mean of columns: 3,152,100.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #1/100).
    MSE loss, mean of columns: 2,955,429.500000
Done training epoch #1/100 (testing MSE norm (mean) vs. training MSE norm (mean): 13,787,867.000000 (2,836,016.500000) vs. 13,917,953.000000 (2,862,889.250000) (lower is more accurate)).

Beginning epoch #11/100.
  Beginning sample #1/6,327 (epoch #11/100).
    MSE loss, mean of columns: 2,364,734.250000
  Beginning sample #1,025/6,327 (epoch #11/100).
    MSE loss, mean of columns: 1,726,495.250000
  Beginning sample #2,049/6,327 (epoch #11/100).
    MSE loss, mean of columns: 1,739,765.750000
  Beginning sample #3,009/6,327 (epoch #11/100).
    MSE loss, mean of columns: 1,624,492.250000
  Beginning sample #4,033/6,327 (epoch #11/100).
    MSE loss, mean of columns: 2,728,743.250000
  Beginning sample #5,057/6,327 (testing phase) (epoch #11/100).
    MSE loss, mean of columns: 1,988,047.375000
  Beginning sample #6,017/6,327 (testing phase) (epoch #11/100).
    MSE loss, mean of columns: 1,441,092.625000
Done training epoch #11/100 (testing MSE norm (mean) vs. training MSE norm (mean): 9,056,488.000000 (1,887,271.625000) vs. 8,548,082.000000 (1,786,387.750000) (lower is more accurate)).

Beginning epoch #21/100.
  Beginning sample #1/6,327 (epoch #21/100).
    MSE loss, mean of columns: 1,921,532.750000
  Beginning sample #1,025/6,327 (epoch #21/100).
    MSE loss, mean of columns: 2,154,123.250000
  Beginning sample #2,049/6,327 (epoch #21/100).
    MSE loss, mean of columns: 2,681,038.750000
  Beginning sample #3,009/6,327 (epoch #21/100).
    MSE loss, mean of columns: 1,791,817.375000
  Beginning sample #4,033/6,327 (epoch #21/100).
    MSE loss, mean of columns: 1,916,964.625000
  Beginning sample #5,057/6,327 (testing phase) (epoch #21/100).
    MSE loss, mean of columns: 2,328,037.750000
  Beginning sample #6,017/6,327 (testing phase) (epoch #21/100).
    MSE loss, mean of columns: 2,053,546.625000
Done training epoch #21/100 (testing MSE norm (mean) vs. training MSE norm (mean): 10,843,566.000000 (2,272,351.000000) vs. 10,821,106.000000 (2,267,791.750000) (lower is more accurate)).

Beginning epoch #31/100.
  Beginning sample #1/6,327 (epoch #31/100).
    MSE loss, mean of columns: 2,248,742.500000
  Beginning sample #1,025/6,327 (epoch #31/100).
    MSE loss, mean of columns: 2,419,331.500000
  Beginning sample #2,049/6,327 (epoch #31/100).
    MSE loss, mean of columns: 3,128,976.250000
  Beginning sample #3,009/6,327 (epoch #31/100).
    MSE loss, mean of columns: 1,502,643.250000
  Beginning sample #4,033/6,327 (epoch #31/100).
    MSE loss, mean of columns: 3,318,890.500000
  Beginning sample #5,057/6,327 (testing phase) (epoch #31/100).
    MSE loss, mean of columns: 3,463,680.750000
  Beginning sample #6,017/6,327 (testing phase) (epoch #31/100).
    MSE loss, mean of columns: 2,975,683.250000
Done training epoch #31/100 (testing MSE norm (mean) vs. training MSE norm (mean): 13,641,989.000000 (2,806,526.500000) vs. 14,010,836.000000 (2,877,868.750000) (lower is more accurate)).

Beginning epoch #41/100.
  Beginning sample #1/6,327 (epoch #41/100).
    MSE loss, mean of columns: 2,158,150.750000
  Beginning sample #1,025/6,327 (epoch #41/100).
    MSE loss, mean of columns: 2,440,246.750000
  Beginning sample #2,049/6,327 (epoch #41/100).
    MSE loss, mean of columns: 2,608,803.250000
  Beginning sample #3,009/6,327 (epoch #41/100).
    MSE loss, mean of columns: 2,285,798.500000
  Beginning sample #4,033/6,327 (epoch #41/100).
    MSE loss, mean of columns: 2,184,619.000000
  Beginning sample #5,057/6,327 (testing phase) (epoch #41/100).
    MSE loss, mean of columns: 2,823,894.000000
  Beginning sample #6,017/6,327 (testing phase) (epoch #41/100).
    MSE loss, mean of columns: 3,174,584.500000
Done training epoch #41/100 (testing MSE norm (mean) vs. training MSE norm (mean): 11,972,789.000000 (2,470,997.500000) vs. 11,784,044.000000 (2,417,932.750000) (lower is more accurate)).

Beginning epoch #51/100.
  Beginning sample #1/6,327 (epoch #51/100).
    MSE loss, mean of columns: 2,716,307.750000
  Beginning sample #1,025/6,327 (epoch #51/100).
    MSE loss, mean of columns: 2,849,621.250000
  Beginning sample #2,049/6,327 (epoch #51/100).
    MSE loss, mean of columns: 2,589,270.250000
  Beginning sample #3,009/6,327 (epoch #51/100).
    MSE loss, mean of columns: 2,885,948.500000
  Beginning sample #4,033/6,327 (epoch #51/100).
    MSE loss, mean of columns: 2,419,965.500000
  Beginning sample #5,057/6,327 (testing phase) (epoch #51/100).
    MSE loss, mean of columns: 2,395,394.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #51/100).
    MSE loss, mean of columns: 2,792,379.250000
Done training epoch #51/100 (testing MSE norm (mean) vs. training MSE norm (mean): 12,953,504.000000 (2,667,649.250000) vs. 13,203,428.000000 (2,717,650.750000) (lower is more accurate)).

Beginning epoch #61/100.
  Beginning sample #1/6,327 (epoch #61/100).
    MSE loss, mean of columns: 2,923,164.500000
  Beginning sample #1,025/6,327 (epoch #61/100).
    MSE loss, mean of columns: 3,098,170.250000
  Beginning sample #2,049/6,327 (epoch #61/100).
    MSE loss, mean of columns: 3,573,983.500000
  Beginning sample #3,009/6,327 (epoch #61/100).
    MSE loss, mean of columns: 2,300,330.750000
  Beginning sample #4,033/6,327 (epoch #61/100).
    MSE loss, mean of columns: 2,730,454.250000
  Beginning sample #5,057/6,327 (testing phase) (epoch #61/100).
    MSE loss, mean of columns: 2,365,550.500000
  Beginning sample #6,017/6,327 (testing phase) (epoch #61/100).
    MSE loss, mean of columns: 2,787,491.250000
Done training epoch #61/100 (testing MSE norm (mean) vs. training MSE norm (mean): 13,484,252.000000 (2,773,332.250000) vs. 14,745,178.000000 (3,012,898.500000) (lower is more accurate)).

Beginning epoch #71/100.
  Beginning sample #1/6,327 (epoch #71/100).
    MSE loss, mean of columns: 2,693,039.000000
  Beginning sample #1,025/6,327 (epoch #71/100).
    MSE loss, mean of columns: 2,824,063.000000
  Beginning sample #2,049/6,327 (epoch #71/100).
    MSE loss, mean of columns: 2,541,486.000000
  Beginning sample #3,009/6,327 (epoch #71/100).
    MSE loss, mean of columns: 2,852,223.750000
  Beginning sample #4,033/6,327 (epoch #71/100).
    MSE loss, mean of columns: 2,638,139.500000
  Beginning sample #5,057/6,327 (testing phase) (epoch #71/100).
    MSE loss, mean of columns: 2,252,567.750000
  Beginning sample #6,017/6,327 (testing phase) (epoch #71/100).
    MSE loss, mean of columns: 2,550,344.750000
Done training epoch #71/100 (testing MSE norm (mean) vs. training MSE norm (mean): 13,023,068.000000 (2,692,758.500000) vs. 13,062,926.000000 (2,698,479.250000) (lower is more accurate)).

Beginning epoch #81/100.
  Beginning sample #1/6,327 (epoch #81/100).
    MSE loss, mean of columns: 2,896,907.000000
  Beginning sample #1,025/6,327 (epoch #81/100).
    MSE loss, mean of columns: 2,699,186.500000
  Beginning sample #2,049/6,327 (epoch #81/100).
    MSE loss, mean of columns: 2,813,396.750000
  Beginning sample #3,009/6,327 (epoch #81/100).
    MSE loss, mean of columns: 2,918,460.500000
  Beginning sample #4,033/6,327 (epoch #81/100).
    MSE loss, mean of columns: 2,938,282.500000
  Beginning sample #5,057/6,327 (testing phase) (epoch #81/100).
    MSE loss, mean of columns: 2,773,403.000000
  Beginning sample #6,017/6,327 (testing phase) (epoch #81/100).
    MSE loss, mean of columns: 3,136,527.000000
Done training epoch #81/100 (testing MSE norm (mean) vs. training MSE norm (mean): 14,361,930.000000 (2,961,079.750000) vs. 14,551,386.000000 (2,995,309.500000) (lower is more accurate)).

Beginning epoch #91/100.
  Beginning sample #1/6,327 (epoch #91/100).
    MSE loss, mean of columns: 3,217,999.500000
  Beginning sample #1,025/6,327 (epoch #91/100).
    MSE loss, mean of columns: 2,457,931.000000
  Beginning sample #2,049/6,327 (epoch #91/100).
    MSE loss, mean of columns: 3,045,961.000000
  Beginning sample #3,009/6,327 (epoch #91/100).
    MSE loss, mean of columns: 1,399,607.625000
  Beginning sample #4,033/6,327 (epoch #91/100).
    MSE loss, mean of columns: 3,332,276.000000
  Beginning sample #5,057/6,327 (testing phase) (epoch #91/100).
    MSE loss, mean of columns: 3,372,476.750000
  Beginning sample #6,017/6,327 (testing phase) (epoch #91/100).
    MSE loss, mean of columns: 2,861,580.500000
Done training epoch #91/100 (testing MSE norm (mean) vs. training MSE norm (mean): 13,541,661.000000 (2,765,119.000000) vs. 13,660,983.000000 (2,787,410.500000) (lower is more accurate)).

Done training last epoch.  Preparing statistics...

Last testing MSE   (norm) (mean) : <        45.142471,        688.518311,      1,587.326050, 10,970,917.000000,    420,898.218750> (10,978,988.000000) ( 2,278,827.250000)
Last testing RMSE  (norm) (mean) : <         6.718815,         26.239632,         39.841259,      3,312.237549,        648.766663> (     3,375.520264) (       806.760803)
Last training MSE  (norm) (mean) : <        44.900677,        690.337463,      1,567.502441, 10,806,500.000000,    410,542.781250> (10,814,296.000000) ( 2,243,869.250000)
Last training RMSE (norm) (mean) : <         6.700797,         26.274273,         39.591698,      3,287.324219,        640.736145> (     3,349.529297) (       800.125427)

Label column names               : <         kdiff[%],         Bleak[uT],    V_PriWind[cm3],    V_PriCore[cm3],           Pout[W]>

(Reversed model: labels are simulation outputs, not inputs.)
All labels mean    (norm) (mean) : <         9.776808,         26.101175,         88.323395,      3,365.576172,        656.228149> (     3,430.206299) (       829.201172)
All labels var     (norm) (mean) : <        19.390743,        399.580109,        620.851685,  6,775,504.500000,    193,356.734375> ( 6,778,263.000000) ( 1,393,980.250000)
All labels stddev  (norm) (mean) : <         4.403492,         19.989500,         24.916895,      2,602.979980,        439.723480> (     2,640.057129) (       618.402649)

All labels min     (norm) (mean) : <         0.012835,          2.900000,         38.160000,        800.000000,         50.312965> (       802.493591) (       178.277161)
...1st quartile    (norm) (mean) : <         7.866466,         12.751261,         67.320000,      1,250.000000,        309.686279> (     1,289.636475) (       329.524811)
All labels median  (norm) (mean) : <        10.647444,         20.200001,         88.919998,      2,450.000000,        513.998108> (     2,505.019287) (       616.753052)
...3rd quartile    (norm) (mean) : <        12.842000,         32.799999,        107.279999,      5,000.000000,        925.467468> (     5,086.181152) (     1,215.677856)
All labels max     (norm) (mean) : <        17.763830,        153.600006,        140.759995,      8,450.000000,      1,968.984619> (     8,678.889648) (     2,146.221680)

Wrote MSE errors (testing MSE for each epoch and then training MSE for each epoch) to `dist/reversed_train_dense_mse_01_repeat.csv'.

Saved trained model to `dist/reversed_dense.pt'.

Done training all epochs.
Have a good day.
